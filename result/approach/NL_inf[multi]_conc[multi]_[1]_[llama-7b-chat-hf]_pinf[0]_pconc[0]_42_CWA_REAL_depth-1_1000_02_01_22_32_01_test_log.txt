02/01/2024 22:32:01   **info                              [test]
02/01/2024 22:32:01   seed                                [42]
02/01/2024 22:32:01   model                               [meta-llama/Llama-2-7b-chat-hf]
02/01/2024 22:32:01   model_short                         [llama-7b-chat-hf]
02/01/2024 22:32:01   mode_inference                      [multi]
02/01/2024 22:32:01   mode_conclusion                     [multi]
02/01/2024 22:32:01   nr_prompt_inference                 [0]
02/01/2024 22:32:01   nr_prompt_conclusion                [0]
02/01/2024 22:32:01   n_step                              [1]
02/01/2024 22:32:01   arg dataset_name                    [proofwriter_6000]
02/01/2024 22:32:01   arg data_file_name                  [CWA_REAL_depth-1_1000]
02/01/2024 22:32:01   torch_dtype                         [torch.float16]
02/01/2024 22:32:01   dataset_file_full_path              [/dss/dsshome1/0A/di35fer/dataset/proofwriter_6000/CWA_REAL_depth-1_1000.jsonl]
02/01/2024 22:32:01   path_output_log                     [/dss/dsshome1/0A/di35fer/code/code_vanilla/result/module/proofwriter_6000/NL_inf[multi]_conc[multi]_[1]_[llama-7b-chat-hf]_pinf[0]_pconc[0]_42_CWA_REAL_depth-1_1000_02_01_22_32_01_test_log.txt]
02/01/2024 22:32:01   output_file_path                    [/dss/dsshome1/0A/di35fer/code/code_vanilla/result/module/proofwriter_6000/NL_inf[multi]_conc[multi]_[1]_[llama-7b-chat-hf]_pinf[0]_pconc[0]_42_CWA_REAL_depth-1_1000_02_01_22_32_01_test_res.csv]
02/01/2024 22:32:01   Starting new HTTPS connection (1): huggingface.co:443
02/01/2024 22:32:01   https://huggingface.co:443 "HEAD /meta-llama/Llama-2-7b-chat-hf/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
02/01/2024 22:32:02   https://huggingface.co:443 "HEAD /meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json HTTP/1.1" 200 0
02/01/2024 22:32:04   We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
02/01/2024 22:32:20   https://huggingface.co:443 "HEAD /meta-llama/Llama-2-7b-chat-hf/resolve/main/generation_config.json HTTP/1.1" 200 0
02/01/2024 22:32:20   Starting new HTTPS connection (1): s3.amazonaws.com:443
02/01/2024 22:32:20   https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/json/json.py HTTP/1.1" 200 0
02/01/2024 22:32:20   open file: /dss/dsshome1/0A/di35fer/.cache/huggingface/datasets/json/default-aacad5b4af56e685/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json
02/01/2024 22:32:20   open file: /dss/dsshome1/0A/di35fer/.cache/huggingface/datasets/json/default-aacad5b4af56e685/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/dataset_info.json
02/01/2024 22:54:04   nr      [200]
02/01/2024 23:15:48   nr      [400]
02/01/2024 23:38:29   nr      [600]
02/02/2024 00:01:50   nr      [800]
02/02/2024 00:25:17   nr      [1000]
02/02/2024 00:25:17   finished
